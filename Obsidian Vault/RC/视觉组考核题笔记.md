## 简历

**陈冠廷**
电气工程学院 自动化系 2023级
必修均分89.74
四川大学校级优秀干部

**科研竞赛经历**：
- 中国机器人与人工智能大赛省赛一等奖、国赛二等奖
- 一篇论文在投

**下⼀学年的计划**：
- 参加数学建模国赛
- 加入RC川山甲战队
- 保研准备

**视觉组工作的理解**：
- 实现机器人的环境感知、目标检测/识别、位姿计算，还要与其他模块进行通信
- 比如今年的RoboCon比赛中，就需要视觉组实现对篮板的定位，从而帮助机器人进行投篮的瞄准


## 一、Github账号
[Getting05 (Getting)](https://github.com/Getting05)
## 二、Ubuntu 系统（双系统）
原先装好的
参考资料：
[Ubuntu20.04双系统安装详解（内容详细，一文通关！）_ubuntu 20.04-CSDN博客](https://blog.csdn.net/wyr1849089774/article/details/133387874)
[Windows 和 Ubuntu 双系统的安装和卸载_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1554y1n7zv/?spm_id_from=333.337.search-card.all.click)
[Windows11 安装 Ubuntu 避坑指南_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1Cc41127B9/?spm_id_from=333.337.search-card.all.click)
## 三、非预备队员请完成预备队员考核题中的OpenCV部分题目
### 篮板检测
https://github.com/Getting05/RC_backboard_detection
#### 问题分析
##### 算法思路
1. **预处理**: 将彩色图像转为灰度，应用高斯模糊去噪
2. **边缘检测**: 使用Canny算法检测边缘
3. **轮廓提取**: 从边缘图像中提取轮廓
4. **形状筛选**: 根据**面积和形状特征**筛选篮板候选区域
5. **中心计算**: 使用几何中心计算篮板中心
6. **结果标记**: 在原图上用红点标记检测结果
难点在于其第4步，因为图像最经过边缘处理后反而篮板部分不会出现一个较好的矩形，如下图：
![[Pasted image 20250802230331.png]]
![[1754147097443.png]]
这将导致采用这种方法进行检测的时候无法直接检测到篮板的矩形框。
观察到篮板上还有很多标记构成矩形，于是产生新思路：**通过找到包含”矩形样“ 最多的区域来找到篮筐区域，最后能够框住该区域的最小矩形框便是篮板区域。**
#### 具体操作
##### 0. 环境安装
新建一个opencv环境用于该项目完成，同时需要在其中增加jupyter内核
``` bash
conda create -n opencv python=3.11
conda init
conda activate opencv
pip install opencv-python numpy
python -m ipykernel install --user --name opencv --display-name opencv
```


##### 1. 环境配置和库导入

首先安装和导入必要的Python库：

``` python
# 安装必要的库（如果还未安装）
import subprocess
import sys

def install_package(package):
    """安装Python包的辅助函数"""
    try:
        subprocess.check_call([sys.executable, "-m", "pip", "install", package])
        print(f"成功安装 {package}")
    except subprocess.CalledProcessError:
        print(f"安装 {package} 失败")

# 安装需要的包
packages = ['opencv-python', 'numpy', 'matplotlib']
for package in packages:
    install_package(package)


# 导入必要的库
import cv2                    # OpenCV库，用于计算机视觉处理
import numpy as np           # NumPy库，用于数值计算
import matplotlib.pyplot as plt  # Matplotlib库，用于图像显示
import os                    # 操作系统接口，用于文件路径处理

print("库导入成功！")
print(f"OpenCV版本: {cv2.__version__}")
print(f"NumPy版本: {np.__version__}")
```
库导入成功！ 
OpenCV版本: 4.12.0 
NumPy版本: 2.0.1
##### 2. 图像加载和预处理

加载目标图像并进行初步处理：
``` python
plt.rcParams['font.sans-serif'] = ['SimHei'] # 设置字体为黑体
plt.rcParams['axes.unicode_minus'] = False # 解决负号显示问题

# 定义图像路径
image_path = 'task1_1.png'

# 检查文件是否存在
if not os.path.exists(image_path):
    print(f"错误：找不到图像文件 {image_path}")
else:
    print(f"找到图像文件: {image_path}")

# 使用OpenCV加载图像
# cv2.imread()函数加载图像，默认为BGR颜色空间
image_bgr = cv2.imread(image_path)

if image_bgr is None:
    print("错误：无法加载图像")
else:
    # 将BGR转换为RGB（matplotlib使用RGB格式显示）
    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
    
    # 显示原始图像信息
    height, width, channels = image_rgb.shape
    print(f"图像尺寸: {width} x {height} 像素")
    print(f"颜色通道数: {channels}")
    
    # 显示原始图像
    plt.figure(figsize=(12, 8))
    plt.imshow(image_rgb)
    plt.title('原始图像')
    plt.axis('off')
    plt.show()
```
![[Pasted image 20250803113840.png]]
##### 3. 图像预处理

为了更好地检测篮板，我们需要对图像进行预处理：
``` python
# 转换为灰度图像
# 灰度图像处理速度更快，且对于边缘检测更有效
gray = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)

# 应用高斯模糊减少噪声
# (5,5)是卷积核大小，0是标准差（自动计算）
blurred = cv2.GaussianBlur(gray, (5, 5), 0)

# 使用Canny边缘检测
# 50和150是低阈值和高阈值
edges = cv2.Canny(blurred, 50, 150)

# 显示预处理结果
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

axes[0].imshow(gray, cmap='gray')
axes[0].set_title('灰度图像')
axes[0].axis('off')

axes[1].imshow(blurred, cmap='gray')
axes[1].set_title('高斯模糊后')
axes[1].axis('off')

axes[2].imshow(edges, cmap='gray')
axes[2].set_title('Canny边缘检测')
axes[2].axis('off')

plt.tight_layout()
plt.show()
```
![[Pasted image 20250803113818.png]]
##### 4. 轮廓检测和筛选

检测图像中的轮廓，并筛选出可能的篮板轮廓：
``` python
# 查找轮廓
# cv2.RETR_EXTERNAL: 只检测外部轮廓
# cv2.CHAIN_APPROX_SIMPLE: 压缩轮廓，只保留端点
contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

print(f"检测到 {len(contours)} 个轮廓")

# 创建原图副本用于绘制轮廓
contour_image = image_rgb.copy()

# 绘制所有轮廓
cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 2)

# 显示轮廓检测结果
plt.figure(figsize=(12, 8))
plt.imshow(contour_image)
plt.title('检测到的所有轮廓')
plt.axis('off')
plt.show()

# 筛选轮廓：根据面积和形状特征
potential_backboards = []

# 计算图像总面积用于相对面积判断
image_area = width * height

for i, contour in enumerate(contours):
    # 计算轮廓面积
    area = cv2.contourArea(contour)
    
    # 计算轮廓周长
    perimeter = cv2.arcLength(contour, True)
    
    # 多边形近似
    # epsilon是近似精度，通常设为周长的2%
    epsilon = 0.01 * perimeter
    approx = cv2.approxPolyDP(contour, epsilon, True)
    
    # 计算边界矩形
    x, y, w, h = cv2.boundingRect(contour)
    
    # 计算宽高比
    aspect_ratio = w / h if h > 0 else 0
    
    # 计算轮廓的矩形度（轮廓面积与边界矩形面积的比值）
    rect_area = w * h
    extent = area / rect_area if rect_area > 0 else 0
    
    # 更宽松的筛选条件：
    # 1. 面积要足够大（降低阈值）
    # 2. 宽高比合理（篮板通常是矩形，宽度大于高度）
    # 3. 矩形度合理（形状接近矩形）
    # 4. 相对面积不能太小
    if (area > 500 and  # 降低面积阈值
        0.5 < aspect_ratio < 5.0 and  # 宽松的宽高比限制
        extent > 0.3 and  # 矩形度要求
        area / image_area > 0.01):  # 相对面积要求
        
        potential_backboards.append({
            'contour': contour,
            'area': area,
            'approx': approx,
            'aspect_ratio': aspect_ratio,
            'extent': extent,
            'bbox': (x, y, w, h),
            'index': i
        })
        print(f"潜在篮板 {i}: 面积={area:.0f}, 顶点数={len(approx)}, 宽高比={aspect_ratio:.2f}, 矩形度={extent:.2f}")

# 如果还是没找到，进一步放宽条件
if len(potential_backboards) == 0:
    print("使用更宽松的条件重新筛选...")
    for i, contour in enumerate(contours):
        area = cv2.contourArea(contour)
        if area > 3000:  # 最低面积要求
            x, y, w, h = cv2.boundingRect(contour)
            aspect_ratio = w / h if h > 0 else 0
            
            potential_backboards.append({
                'contour': contour,
                'area': area,
                'approx': cv2.approxPolyDP(contour, 0.02 * cv2.arcLength(contour, True), True),
                'aspect_ratio': aspect_ratio,
                'extent': area / (w * h) if w * h > 0 else 0,
                'bbox': (x, y, w, h),
                'index': i
            })
            print(f"候选区域 {i}: 面积={area:.0f}, 宽高比={aspect_ratio:.2f}")

print(f"\n找到 {len(potential_backboards)} 个潜在的篮板轮廓")

```
![[Pasted image 20250803113704.png]]
##### 5. 篮板识别和中心点计算

从筛选出的轮廓中确定篮板，并计算其中心坐标：
``` python
# 如果找到潜在篮板，选择最合适的作为篮板
if potential_backboards:
    print(f"分析 {len(potential_backboards)} 个候选篮板...")
    
    # 为每个候选区域计算得分
    scored_backboards = []
    
    for candidate in potential_backboards:
        score = 0
        area = candidate['area']
        aspect_ratio = candidate['aspect_ratio']
        extent = candidate['extent']
        # 解包候选区域的边界框
        x, y, w, h = candidate['bbox']
        
        # 面积得分（面积越大得分越高，但有上限）
        area_score = min(area / 10000, 10)  # 最高10分
        
        # 宽高比得分（篮板通常宽度大于高度）
        if 1.5 < aspect_ratio < 3.0:
            aspect_score = 10
        elif 1.0 < aspect_ratio < 4.0:
            aspect_score = 5
        else:
            aspect_score = 1
            
        # 矩形度得分（越接近矩形得分越高）
        extent_score = extent * 10
        
        # 位置得分（篮板通常在图像上半部分）
        center_y = y + h // 2
        if center_y < height * 0.6:  # 在图像上60%的位置
            position_score = 5
        else:
            position_score = 1
            
        # 总得分
        total_score = area_score + aspect_score + extent_score + position_score
        
        scored_backboards.append({
            **candidate,
            'total_score': total_score,
            'area_score': area_score,
            'aspect_score': aspect_score,
            'extent_score': extent_score,
            'position_score': position_score
        })
        
        print(f"候选 {candidate['index']}: 总分={total_score:.1f} (面积:{area_score:.1f}, 宽高比:{aspect_score}, 矩形度:{extent_score:.1f}, 位置:{position_score})")
    
    # 选择得分最高的
    backboard = max(scored_backboards, key=lambda x: x['total_score'])
    
    print(f"\n选定篮板 {backboard['index']}：总得分 = {backboard['total_score']:.1f}")
    
    # 计算轮廓的边界矩形
    x, y, w, h = backboard['bbox']
    
    # 计算中心坐标
    center_x = x + w // 2
    center_y = y + h // 2
    
    print(f"篮板中心坐标: ({center_x}, {center_y})")
    print(f"篮板边界框: x={x}, y={y}, width={w}, height={h}")
    print(f"篮板面积: {backboard['area']:.0f}")
```

分析 1 个候选篮板...
候选 29: 总分=17.7 (面积:0.4, 宽高比:10, 矩形度:2.3, 位置:5)

选定篮板 29：总得分 = 17.7
篮板中心坐标: (332, 176)
篮板边界框: x=248, y=130, width=169, height=93
篮板面积: 3675
##### 6. 结果可视化

在原图上标记篮板中心点：
``` python
# 创建结果图像
result_image = image_rgb.copy()


# 如果检测到篮板轮廓，也绘制出来
if potential_backboards:
    cv2.drawContours(result_image, [backboard['contour']], -1, (0, 255, 0), 3)
    
    # 绘制边界框
    x, y, w, h = cv2.boundingRect(backboard['contour'])
    final_result = cv2.rectangle(result_image, (x, y), (x + w, y + h), (0, 0, 255), 2) # 计算包围整个轮廓的最小矩形

#这个矩形框是最终所需篮板框   
#用这个矩形框的xywh计算中心
center_x = x + w // 2
center_y = y + h // 2

# 在图像上绘制红色圆点标记中心
# cv2.circle(图像, 中心点, 半径, 颜色, 线宽)
cv2.circle(result_image, (center_x, center_y), 3, (255, 0, 0), -1)  # 红色实心圆
cv2.circle(result_image, (center_x, center_y), 5, (255, 0, 0), 3)   # 红色圆圈

# 添加文字标注
text = f"center: ({center_x}, {center_y})"
cv2.putText(result_image, text, (center_x - 100, center_y - 30), 
            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)

# 显示最终结果
plt.figure(figsize=(15, 10))
plt.imshow(result_image)
plt.title('篮板检测结果 - 红点标记中心位置', fontsize=16)
plt.axis('off')
plt.show()


# 保存结果图像
result_bgr = cv2.cvtColor(result_image, cv2.COLOR_RGB2BGR)
cv2.imwrite('basketball_detection_result.png', result_bgr)
print("结果已保存为 'basketball_detection_result.png'")
```
![[Pasted image 20250803113755.png]]
*绿色线是潜在轮廓线*
*蓝色线是框住潜在轮廓线的最小矩形框*
*蓝色线是该蓝色线的中心点*
#### 总结
##### 核心OpenCV函数解释

1. **cv2.imread()**: 读取图像文件
2. **cv2.cvtColor()**: 颜色空间转换
3. **cv2.GaussianBlur()**: 高斯模糊，减少噪声
4. **cv2.Canny()**: Canny边缘检测算法
5. **cv2.findContours()**: 查找图像轮廓
6. **cv2.contourArea()**: 计算轮廓面积
7. **cv2.approxPolyDP()**: 多边形近似
8. **cv2.boundingRect()**: 计算边界矩形
9.  **cv2.circle()**: 绘制圆形

## 四、ROS 学习
http://www.autolabor.com.cn/book/ROSTutorials/
https://www.bilibili.com/video/BV1Ci4y1L7ZZ
具体详细记录：
[[ROS_赵虚左]]
仓库地址：
https://github.com/Getting05/ROS_topic_communication
结果如图：
![[2025-08-18 11-54-12 的屏幕截图 1.png]]
![[2025-08-18 11-54-25 的屏幕截图 2.png]]

## 五、二选一 

- 深度学习感知方向：使用 KITTI 数据集复现 Pointpillar 算法，使用任意点云数据展示检测的结果。 
	- 附加题：删去数据集中的 calib 、 image 文件，仅使用点云数据完成算法的训练。

- 自主导航方向：使用 ros 、 gazebo ，完成完整的自主移动仿真系统。包括机器人模型的 urdf 编写（建议 DIY ），环境的搭建（建议 DIY ）， navigation/navigation2 的部署 ( 全部使用官方例程实现即可 ) 视频展示导航效果。 
	- 附加题：自行寻找其他开源 Slam 算法，部署于仿真环境中。

#### 深度学习感知方向
仓库地址：
https://github.com/Getting05/OpenPCDet
论文地址：
https://openaccess.thecvf.com/content_CVPR_2019/papers/Lang_PointPillars_Fast_Encoders_for_Object_Detection_From_Point_Clouds_CVPR_2019_paper.pdf

使用OpenPCDet 复现 Pointpillars
##### 0.  配置环境
python\==3.8
CUDA\==11.3
conda install pytorch\==1.12.1 torchvision\==0.13.1 torchaudio\==0.12.1 cudatoolkit\==11.3 -c pytorch

```

pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113
```
```
conda create -n pcdet python=3.8 cudatoolkit=11.3
conda activate pcdet
pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1


(pcdet) getting@PC:~/OpenPCDet$ python -c "import torch;print(torch.__version__);print(torch.cuda.is_available());print(torch.version.cuda)"
1.11.0+cu113
True
11.3
```
##### 1.  安装相应的spconv
https://github.com/traveller59/spconv
```
pip install spconv-cu113
```

```
(pcdet) getting@PC:~/OpenPCDet$ python -c "import spconv"
```
无输出则验证安装成功
##### 2. 克隆仓库&安装依赖
```
git clone https://github.com/Getting05/OpenPCDet.git

cd ~/OpenPCDet
conda activate pcdet

pip install -r requirements.txt 
python setup.py develop #安装OpenPCDet库
```
此处由于系统cuda版本的问题一直报错。
由于原本安装的是cuda12.9，因此需要再安装cuda11.3版本，这里选择安装多版本的方法。

###### cuda多版本安装经验总结：

可以把usr/local/中的cuda文件放在容量大的地方（如/home/下），在~/.bashrc文件下对应进行路径的更改即可
```
#原路径
export PATH=/usr/local/cuda/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH

#修改后的路径
export PATH=/home/getting/cuda/cuda-12.9/bin:$PATH
export LD_LIBRARY_PATH=/home/getting/cuda/cuda-12.9/lib64:$LD_LIBRARY_PATH
```

##### 3. 用预训练模型进行测试
1. kitti数据集下载和准备
https://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d
通过如下链接下载。
	- [Download Velodyne point clouds, if you want to use laser information (29 GB)](https://s3.eu-central-1.amazonaws.com/avg-kitti/data_object_velodyne.zip)
	- https://s3.eu-central-1.amazonaws.com/avg-kitti/data_object_image_2.zip
	- https://s3.eu-central-1.amazonaws.com/avg-kitti/data_object_calib.zip
	- https://s3.eu-central-1.amazonaws.com/avg-kitti/data_object_label_2.zip
2. 安装可视化工具
```bash
pip install open3d
```
3. 下载预训练模型
https://github.com/Getting05/OpenPCDet/blob/master/README.md
下载pointpillar：https://drive.google.com/file/d/1wMxWTpU1qUoY3DsCH31WJmvJxcjFXKlm/view?pli=1
解压缩，放入OpenPCDet/data/kiti/
```
.
├── ImageSets
├── testing
│   ├── calib
│   ├── image_2
│   └── velodyne
└── training
    ├── calib
    ├── image_2
    ├── label_2
    └── velodyne
```


4. 使用预训练模型和kitti数据集进行演示
```
python demo.py --cfg_file cfgs/kitti_models/pointpillar.yaml \
    --ckpt /home/getting/桌面/pointpillar_7728.pth \
    --data_path /home/getting/OpenPCDet/data/kiti/testing/velodyne
```
结果如图(第一张)
![[2025-08-06 22-18-33 的屏幕截图.png]]
##### 4.运行以下代码生成相应的数据集配置文件
```
python -m pcdet.datasets.kitti.kitti_dataset create_kitti_infos tools/cfgs/dataset_configs/kitti_dataset.yaml
```

##### 5. 开始训练
进入tools

```
cd tools #进入配置文件的文件夹
```

如果运行pointpillars，则输入以下命令

```
python train.py --cfg_file cfgs/kitti_models/pointpillar.yaml
```
遇到报错
   sampled_gt_boxes, data_dict['road_plane'], data_dict['calib']
KeyError: 'road_plane'

修改/home/pc/OpenPCDet/tools/cfgs/kitti_models/pointpillar.yaml
第27行
```
 USE_ROAD_PLANE: False

```
/home/pc/OpenPCDet/tools/cfgs/dataset_configs/kitti_dataset.yaml
第23行
```
USE_ROAD_PLANE: False
```

继续遇到报错：
RuntimeError: CUDA out of memory. Tried to allocate 314.00 MiB (GPU 0; 7.60 GiB total capacity; 3.74 GiB already allocated; 248.31 MiB free; 5.32 GiB allowed; 4.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
 修改/home/pc/OpenPCDet/tools/cfgs/kitti_models/pointpillar.yaml
 第146行
```
 BATCH_SIZE_PER_GPU: 1
```
历经八小时训练成功
2025-08-07 21:13:13,467   INFO  *************** Performance of EPOCH 80 *****************
2025-08-07 21:13:13,468   INFO  Generate label finished(sec_per_example: 0.0556 second).
2025-08-07 21:13:13,468   INFO  recall_roi_0.3: 0.000000
2025-08-07 21:13:13,468   INFO  recall_rcnn_0.3: 0.882902
2025-08-07 21:13:13,468   INFO  recall_roi_0.5: 0.000000
2025-08-07 21:13:13,468   INFO  recall_rcnn_0.5: 0.820822
2025-08-07 21:13:13,468   INFO  recall_roi_0.7: 0.000000
2025-08-07 21:13:13,468   INFO  recall_rcnn_0.7: 0.591582
2025-08-07 21:13:13,470   INFO  Average predicted number of objects(3769 samples): 18.146

训练的模型结果保存在`/home/getting/OpenPCDet/output/kitti_models/pointpillar/default/ckpt/latest_model.pth`

##### 6.tensorboard

```
tensorboard --logdir="/home/getting/OpenPCDet/output/kitti_models/pointpillar/default/tensorboard"

```
TensorBoard 2.11.0 at http://localhost:6006/ (Press CTRL+C to quit)

![[2025-08-07 23-25-22 的屏幕截图.png]]

##### 7. 模型测试
```
cd ~/OpenPCDet/tools
python demo.py --cfg_file cfgs/kitti_models/pointrcnn.yaml --data_path ../data/kitti/testing/velodyne/000005.bin --ckpt ../output/kitti_models/pointpillar/default/ckpt/latest_model.pth
```

![[2025-08-07 23-31-40 的屏幕截图.png]]

至此完成该题目。

参考资料：
[基于kitti数据集的3D目标检测算法的训练流程_kitti 3d目标检测-CSDN博客](https://blog.csdn.net/qq_52889317/article/details/142493672?spm=1001.2014.3001.5501)
[open-mmlab/OpenPCDet: OpenPCDet Toolbox for LiDAR-based 3D Object Detection.](https://github.com/open-mmlab/OpenPCDet)
[zhulf0804/PointPillars: A Simple PointPillars PyTorch Implementation for 3D LiDAR(KITTI) Detection.](https://github.com/zhulf0804/PointPillars?tab=readme-ov-file)
[Pointpillar算法复现结果分析_pointpillar复现-CSDN博客](https://blog.csdn.net/qq_52889317/article/details/142786260)
https://zhuanlan.zhihu.com/p/2835189199
##### 附加题

在 `cfgs/dataset_configs/kitti_dataset.yaml`
将 `FOV_POINTS_ONLY` 设置为 `False`。

**核心问题：**
1.  **训练阶段：** `kitti_dataset.py` 的 `__getitem__` 方法会无条件调用 `self.get_calib()`，在找不到 calib 文件时触发断言错误。
2.  **评估阶段：** `generate_prediction_dicts` 方法在处理预测结果时，假定 `batch_dict` 中必然存在 `calib` 键，当 calib 文件未加载时，导致 `KeyError`。

**修改方案：**

**1. kitti_dataset.py - `__getitem__` 方法修改：**

*   **条件加载 `calib`**：
    修改了 `calib` 对象的获取逻辑。之前是强制加载，现在仅当配置文件中的 `FOV_POINTS_ONLY` 选项为 `True` 时才加载 `calib` 文件。当该选项为 `False` 时，`calib` 对象为 `None`。

    ```python
    # ...
    calib = self.get_calib(sample_idx) if self.dataset_cfg.get('FOV_POINTS_ONLY', True) else None
    # ...
    ```

*   **兼容无 `calib` 的数据处理**：
    在后续所有使用到 `calib` 对象的地方（如真值框坐标系转换、点云FOV过滤等），都增加了 `if calib is not None:` 的判断，确保在 `calib` 为 `None` 的情况下跳过相关处理，避免程序出错。

**2. kitti_dataset.py - `generate_prediction_dicts` 方法修改：**

*   **处理无 `calib` 的预测结果**：
    在内部嵌套函数 `generate_single_sample_dict` 中，增加了对 `batch_dict` 中是否存在 `'calib'` 键的检查。
    *   如果 **存在** `'calib'`，则执行原有的逻辑，将激光雷达坐标系下的预测框转换为相机坐标系和图像坐标系。
    *   如果 **不存在** `'calib'`，则跳过所有坐标转换步骤，直接将模型输出的激光雷达坐标系下的预测框 (`pred_boxes`)、类别 (`name`) 和分数 (`score`) 存入结果字典。

    ```python
    # in generate_single_sample_dict function
    # ...
    if 'calib' not in batch_dict:
        pred_dict['name'] = np.array(class_names)[pred_labels - 1]
        pred_dict['score'] = pred_scores
        pred_dict['boxes_lidar'] = pred_boxes
        return pred_dict
    # ...
    ```

**最终效果：**
*   **训练和评估不再崩溃**：通过上述修改，即使数据集中没有提供 `calib` 文件，只要将配置文件 `FOV_POINTS_ONLY` 设置为 `False`，训练和评估流程也能顺利运行。

可以看到正常开始训练了。
![[2025-08-26 19-15-22 的屏幕截图.png]]

#### 自主导航方向
这方向我没有重点去完成，不过在之前的一个相关项目的过程中我有所接触，可见我仓库：
[Getting05/Sweeping-Robot: Sweeping robot simulation in ROS(Noetic)](https://github.com/Getting05/Sweeping-Robot)
[Getting05/tiago_public_ws](https://github.com/Getting05/tiago_public_ws)

